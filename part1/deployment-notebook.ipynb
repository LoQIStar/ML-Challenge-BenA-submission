{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer Model Optimization for Deployment\n",
    "This notebook implements the optimization pipeline for deploying a Vision Transformer model with quantization. It focuses on practical implementation and deployment considerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.ao.quantization import get_default_qconfig\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 224\n",
    "MODEL_PATH = 'optimized_model.pth'\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model and Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transform_pipeline():\n",
    "    \"\"\"Create standard preprocessing pipeline for inference\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.CenterCrop(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "def load_vit_model():\n",
    "    \"\"\"Load and prepare ViT model for deployment\"\"\"\n",
    "    model = torch.hub.load('facebookresearch/dino:main', 'dino-vitb16')\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOptimizer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def quantize(self):\n",
    "        \"\"\"Quantize model for deployment\"\"\"\n",
    "        quantized_model = torch.quantization.quantize_dynamic(\n",
    "            self.model,\n",
    "            {torch.nn.Linear},\n",
    "            dtype=torch.qint8\n",
    "        )\n",
    "        return quantized_model\n",
    "    \n",
    "    def get_model_size(self, model):\n",
    "        \"\"\"Calculate model size in MB\"\"\"\n",
    "        param_size = sum(p.nelement() * p.element_size() for p in model.parameters())\n",
    "        buffer_size = sum(b.nelement() * b.element_size() for b in model.buffers())\n",
    "        return (param_size + buffer_size) / 1024**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deployment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeploymentPipeline:\n",
    "    def __init__(self):\n",
    "        self.transform = create_transform_pipeline()\n",
    "        self.model = None\n",
    "    \n",
    "    def optimize_for_deployment(self):\n",
    "        \"\"\"Prepare optimized model for deployment\"\"\"\n",
    "        # Load model\n",
    "        model = load_vit_model()\n",
    "        optimizer = ModelOptimizer(model)\n",
    "        \n",
    "        # Optimize model\n",
    "        print(\"Original model size: {:.2f} MB\".format(\n",
    "            optimizer.get_model_size(model)\n",
    "        ))\n",
    "        \n",
    "        optimized_model = optimizer.quantize()\n",
    "        print(\"Optimized model size: {:.2f} MB\".format(\n",
    "            optimizer.get_model_size(optimized_model)\n",
    "        ))\n",
    "        \n",
    "        self.model = optimized_model\n",
    "        return optimized_model\n",
    "    \n",
    "    def save_model(self, path=MODEL_PATH):\n",
    "        \"\"\"Save optimized model\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not optimized yet\")\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "        print(f\"Model saved to {path}\")\n",
    "    \n",
    "    def load_model(self, path=MODEL_PATH):\n",
    "        \"\"\"Load optimized model\"\"\"\n",
    "        self.model = load_vit_model()\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "        self.model.eval()\n",
    "        return self.model\n",
    "    \n",
    "    def inference(self, image):\n",
    "        \"\"\"Run inference on single image\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            image = self.transform(image).unsqueeze(0).to(DEVICE)\n",
    "            output = self.model(image)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploy Optimized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main deployment pipeline\"\"\"\n",
    "    # Initialize pipeline\n",
    "    pipeline = DeploymentPipeline()\n",
    "    \n",
    "    # Optimize and save model\n",
    "    print(\"Optimizing model...\")\n",
    "    pipeline.optimize_for_deployment()\n",
    "    pipeline.save_model()\n",
    "    \n",
    "    # Verify deployment\n",
    "    print(\"\\nVerifying deployment...\")\n",
    "    loaded_model = pipeline.load_model()\n",
    "    print(\"Model loaded successfully\")\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    deployment_pipeline = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def process_image(image_path, pipeline):\n",
    "    \"\"\"Example of processing a single image\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    output = pipeline.inference(image)\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "# output = process_image('example.jpg', deployment_pipeline)"
   ]
  }
 ]
}
